---
title: "New York City Taxi Trip Duration - EDA"
date: '`r Sys.Date()`'
output: 
  html_document:
    number_sections: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
    highlight: tango
    code_folding: hide
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo=TRUE, error=FALSE)
```

# Introduction
This is a school mini-project about data mining in University Jean Monnet, ST Etienne, France. The subject of project is open, so I choose this Kaggle's competition to pratice my skills, and to have some ideas about real-life problems in Data Science. At the moment I write this notebook, the competition has been closed already. All information about the competition, you can find at [Kaggle](https://www.kaggle.com/c/nyc-taxi-trip-duration).

This notebook is an Exploratory Data Analysis for the [New York City Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration) competition and inspired by [the awesome EDA](https://www.kaggle.com/headsortails/nyc-taxi-eda-update-the-fast-the-curious/notebook) of [Heads or Tails](https://www.kaggle.com/headsortails) in the forum.

This project aime to build a model that is able to predict the total ride duration of taxi trips in New York City. We have 2 files `.csv` to train and test the model. However, we also need 2 external data sets on [NYC weather](https://www.kaggle.com/mathijs/weather-data-in-new-york-city-2016) and on the theoretically [fastest routes](https://www.kaggle.com/oscarleo/new-york-city-taxi-with-osrm).

At the end of this project, we hope to have a *XGBoost model* that provides a basic prediction.

## Libraries

```{r, message = FALSE}
library('ggplot2') # visualisation
library('scales') # visualisation
library('grid') # visualisation
library('RColorBrewer') # visualisation
library('corrplot') # visualisation
library('alluvial') # visualisation
library('dplyr') # data manipulation
library('readr') # input/output
library('data.table') # data manipulation
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('stringr') # string manipulation
library('forcats') # factor manipulation
library('lubridate') # date and time
library('geosphere') # geospatial locations
library('leaflet') # maps
library('leaflet.extras') # maps
library('maps') # maps
library('xgboost') # modelling
library('caret') # modelling
```

```{r}
# Define multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```
## Load Data
we can use `tibble` library to speed up loading data:

```{r warning=FALSE, results=FALSE}
my_path = "E:/MLDM/Project/DataMiningProject/"
setwd(my_path)

train <- as.tibble(fread('./data/train.csv'))
test <- as.tibble(fread('./data/test.csv'))
sample_submit <- as.tibble(fread('./data/sample_submission.csv'))
```

Data's features:
```{r}
glimpse(train)
```

we aware that:

- `vendor_id` is only 1 or 2, so maybe this is 2 different taxi companies

- `pickup` and `dropoff` describe the time and the coordinates where the meter engage and disengage 

- `store_and_fwd_flag` indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server - Y=store and forward; N=not a store and forward trip

- `trip_duration` duration of a trip in second

## Missing values
It is important to know if the data miss values or not. To check this, we can use function `is.na()`:

```{r}
sum(is.na(train))
sum(is.na(test))
```
We can see that there is no missing values in our data!

## Reformating features

```{r}
train <- train %>%
  mutate(pickup_datetime = ymd_hms(pickup_datetime),
         dropoff_datetime = ymd_hms(dropoff_datetime),
         vendor_id = factor(vendor_id),
         passenger_count = factor(passenger_count))
```

# Visualisations
To understand the features of our data, now we take a look at where taxi diver pickups their clients in NewYork city by using `leaflet` package:
```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 1", out.width="100%"}
set.seed(1234)
foo <- sample_n(train, 8e3)

leaflet(data = foo) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircleMarkers(~ pickup_longitude, ~pickup_latitude, radius = 1,
                   color = "blue", fillOpacity = 0.3)

```

we found that most of trips locate in one part of NewYork, and there are also many trips from/to the JFK airport and La Guardia airport.
Now we'll see the distribution of trips by its duration:

```{r  fig.align = 'default', warning = FALSE, fig.cap ="Fig. 2", out.width="100%"}
train %>%
  ggplot(aes(trip_duration)) +
  geom_histogram(fill = "red", bins = 150) +
  scale_x_log10() +
  scale_y_sqrt()
```

Most of trips is about 1000s, that means ~17min. 
Over the year, the distributions of `pickup_datetime` and `dropoff_datetime` look like:

```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 3", out.width="100%"}
p1 <- train %>%
  ggplot(aes(pickup_datetime)) +
  geom_histogram(fill = "red", bins = 120) +
  labs(x = "Pickup dates")

p2 <- train %>%
  ggplot(aes(dropoff_datetime)) +
  geom_histogram(fill = "blue", bins = 120) +
  labs(x = "Dropoff dates")

layout <- matrix(c(1,2),2,1,byrow=FALSE)
multiplot(p1, p2, layout=layout)
p1 <- 1; p2 <- 1
```

We notice that the number of client is quite stable from Jan to Jul, however there is a drop in Feb.


```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 4", fig.height=6, out.width="100%"}
# p1 <- train %>%
#   group_by(passenger_count) %>%
#   count() %>%
#   ggplot(aes(passenger_count, n, fill = passenger_count)) +
#   geom_col() +
#   scale_y_sqrt() +
#   theme(legend.position = "none")

p1 <- train %>%
  ggplot(aes(passenger_count, fill=passenger_count)) +
  geom_bar() +
  theme(legend.position = "none")

p2 <- train %>%
  ggplot(aes(vendor_id, fill = vendor_id)) +
  geom_bar() +
  theme(legend.position = "none")

p3 <- train %>%
  ggplot(aes(store_and_fwd_flag)) +
  geom_bar() +
  theme(legend.position = "none") +
  scale_y_log10()

p4 <- train %>%
  mutate(wday = wday(pickup_datetime, label = TRUE)) %>%
  group_by(wday, vendor_id) %>%
  count() %>%
  ggplot(aes(wday, n, colour = vendor_id)) +
  geom_point(size = 4) +
  labs(x = "Day of the week", y = "Total number of pickups") +
  theme(legend.position = "none")


p5 <- train %>%
  mutate(hpick = hour(pickup_datetime)) %>%
  group_by(hpick, vendor_id) %>%
  count() %>%
  ggplot(aes(hpick, n, color = vendor_id)) +
  geom_point(size = 4) +
  labs(x = "Hour of the day", y = "Total number of pickups") +
  theme(legend.position = "none")

layout <- matrix(c(1,2,3,4,5,5),3,2,byrow=TRUE)
multiplot(p1, p2, p3, p4, p5, layout=layout)
p1 <- 1; p2 <- 1; p3 <- 1; p4 <- 1; p5 <- 1
```


We find that:

- Most of rides has only 1 passenger.

- The groups of 5 and 6 passengers are more frequent than 3 and 4.

- Vendor 2 sale more tickets than vendor 1 all day of the week and at the end of the week (Fri, Sat) they sell many more tickets than on Monday. 

- The number of trips is stable in the morning and increases at the rush hour in the evening and drop until 5am.

- About 50% of the trip data is not transmitted to vendors immediatly.


```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 5", fig.height=6, out.width="100%"}
p1 <- train %>%
  mutate(hpick = hour(pickup_datetime),
         Month = factor(month(pickup_datetime, label = TRUE))) %>%
  group_by(hpick, Month) %>%
  count() %>%
  ggplot(aes(hpick, n, color = Month)) +
  geom_line(size = 1.5) +
  labs(x = "Hour of the day", y = "count")

p2 <- train %>%
  mutate(hpick = hour(pickup_datetime),
         wday = factor(wday(pickup_datetime, label = TRUE))) %>%
  group_by(hpick, wday) %>%
  count() %>%
  ggplot(aes(hpick, n, color = wday)) +
  geom_line(size = 1.5) +
  labs(x = "Hour of the day", y = "count")

layout <- matrix(c(1,2),2,1,byrow=FALSE)
multiplot(p1, p2, layout=layout)
p1 <- 1; p2 <- 1
```

We also find that June has fewer trips than Mars and at the weekend, people have tendency to go out for night parties so there are more trips in Saturday and Sunday early morning than other days.

# Feature relations
## Pickup date/time vs `trip_duration`
In this section, we'll try to answer the questions following:

- How does the variation in trip numbers throughout the day and the week affect the average trip duration? 

- Do quieter days and hours lead to faster trips? 

```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 7", out.width="100%"}
p1 <- train %>%
  mutate(wday = wday(pickup_datetime, label = TRUE)) %>%
  group_by(wday, vendor_id) %>%
  summarise(median_duration = median(trip_duration)/60) %>%
  ggplot(aes(wday, median_duration, color = vendor_id)) +
  geom_point(size = 4) +
  labs(x = "Day of the week", y = "Median trip duration [min]")

p2 <- train %>%
  mutate(hpick = hour(pickup_datetime)) %>%
  group_by(hpick, vendor_id) %>%
  summarise(median_duration = median(trip_duration)/60) %>%
  ggplot(aes(hpick, median_duration, color = vendor_id)) +
  geom_smooth(method = "loess", span = 1/2) +
  geom_point(size = 4) +
  labs(x = "Hour of the day", y = "Median trip duration [min]") +
  theme(legend.position = "none")

layout <- matrix(c(1,2),2,1,byrow=FALSE)
multiplot(p1, p2, layout=layout)
p1 <- 1; p2 <- 1
```
We find:

- There is indeed a similar pattern as for the business of the day of the week. Vendor 2, the one with the more frequent trips, also has consistently higher trip durations than vendor 1. Therefore, **it will be worth adding the *vendor\_id* feature to a model to test its predictive importance.**

- Over the course of a typical day we find a peak in the early afternoon and dips around 5-6am and 8pm. **The weekday and hour of a trip appear to be important features for predicting its duration and should be included in a successful model.**

## Passenger count and Vendor vs `trip_duration`
Now we want to know the impact of number of passengers on the trip duration. We can use boxplots to figure out this issue.
```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 8", out.width="100%"}
train %>%
  ggplot(aes(passenger_count, trip_duration, color = passenger_count)) +
  geom_boxplot() +
  scale_y_log10() +
  theme(legend.position = "none") +
  facet_wrap(~ vendor_id) +
  labs(y = "Trip duration [s]", x = "Number of passengers")
```

we find that between 1 and 6 passnegers, the trip duration is very similar in both vendors. 

## Store and Forward vs trip_duration
```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 9", out.width="100%"}
train %>%
  filter(vendor_id == 1) %>%
  ggplot(aes(passenger_count, trip_duration, color = passenger_count)) +
  geom_boxplot() +
  scale_y_log10() +
  facet_wrap(~ store_and_fwd_flag) +
  theme(legend.position = "none") +
  labs(y = "Trip duration [s]", x = "Number of passengers") +
  ggtitle("Store_and_fwd_flag impact")
```
We find that there is no overwhelming differences between the stored and non-stored trips. The stored ones might be slightly longer, though, and don’t include any of the suspiciously long trips.

# Feature engineering

In this section we build new features from the existing ones, trying to find better predictors for our target variable.
The new temporal features (date, month, wday, hour) are derived from the pickup_datetime. We got the JFK and La Guardia airport coordinates from Wikipedia. The blizzard feature is based on the external weather data.

```{r}
jfk_coord <- tibble(lon = -73.778889, lat = 40.639722)
la_guardia_coord <- tibble(lon = -73.872611, lat = 40.77725)

pick_coord <- train %>%
  select(pickup_longitude, pickup_latitude)
drop_coord <- train %>%
  select(dropoff_longitude, dropoff_latitude)
train$dist <- distCosine(pick_coord, drop_coord)
train$bearing = bearing(pick_coord, drop_coord)

train$jfk_dist_pick <- distCosine(pick_coord, jfk_coord)
train$jfk_dist_drop <- distCosine(drop_coord, jfk_coord)
train$lg_dist_pick <- distCosine(pick_coord, la_guardia_coord)
train$lg_dist_drop <- distCosine(drop_coord, la_guardia_coord)

train <- train %>%
  mutate(speed = dist/trip_duration*3.6,
         date = date(pickup_datetime),
         month = month(pickup_datetime, label = TRUE),
         wday = wday(pickup_datetime, label = TRUE),
         wday = fct_relevel(wday, c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")),
         hour = hour(pickup_datetime),
         work = (hour %in% seq(8,18)) & (wday %in% c("Mon","Tue","Wed","Thu","Fri")),
         jfk_trip = (jfk_dist_pick < 2e3) | (jfk_dist_drop < 2e3),
         lg_trip = (lg_dist_pick < 2e3) | (lg_dist_drop < 2e3),
         blizzard = !( (date < ymd("2016-01-22") | (date > ymd("2016-01-29"))) )
         )
```
